{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53eca95e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff20dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules.\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import tensorflow as tf2\n",
    "import tabulate\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from pydnet.data import KITTI\n",
    "from pydnet.models import Pydnet\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "# Path to KITTI dataset.\n",
    "KITTI_PATH = Path(\"../\")\\\n",
    "    / \"data\"\\\n",
    "    / \"mount\"\\\n",
    "    / \"KITTI\"\\\n",
    "    / \"raw_data\"\n",
    "\n",
    "# Path to dataset slice index.\n",
    "SLICE_PATH = Path(\"../\")\\\n",
    "    / \"data\"\\\n",
    "    / \"slices\"\\\n",
    "    / \"test_files.txt\"\n",
    "\n",
    "# Path to ground truth file.\n",
    "GROUND_PATH = Path(\"../\")\\\n",
    "    / \"data\"\\\n",
    "    / \"slices\"\\\n",
    "    / \"depths.npz\"\n",
    "\n",
    "# Path to PyDnet pretrained checkpoint.\n",
    "CHECK_PATH = Path(\"../\")\\\n",
    "    / \"data\"\\\n",
    "    / \"checkpoint\"\\\n",
    "    / \"pydnet\"\\\n",
    "    / \"pydnet\"\n",
    "\n",
    "# Path to output.\n",
    "DEST_PATH = Path(\"../\")\\\n",
    "    / \"reports\"\\\n",
    "    / \"evaluation\"\\\n",
    "    / \"KITTI\"\n",
    "\n",
    "# Maximum depth value.\n",
    "MAX_DEPTH = 80.0\n",
    "\n",
    "\n",
    "# Disable Tensorflow warning messages.\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \n",
    "\n",
    "# Run Tensorflow in earger mode.\n",
    "if tf1.executing_eagerly():\n",
    "   tf1.disable_eager_execution()\n",
    "\n",
    "\n",
    "# Utility functions.\n",
    "def read_lines(path: Path) -> list:\n",
    "    \"\"\"Read test files from path.\n",
    "    \"\"\"\n",
    "    assert path.exists()\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    return [l.strip() for l in lines]\n",
    "\n",
    "def compute_errors(\n",
    "    ground: np.ndarray,\n",
    "    pred: np.ndarray\n",
    ") -> [float, float, float, float, float, float, float]:\n",
    "    \"\"\"Compute error metrics using predicted and ground truth depths.\n",
    "    From https://github.com/mrharicot/monodepth/blob/master/utils/evaluation_utils.py\n",
    "    \"\"\"\n",
    "    thresh = np.maximum((ground / pred), (pred / ground))\n",
    "    a1 = (thresh < 1.25).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "    rmse = (ground - pred) ** 2\n",
    "    rmse = np.sqrt(rmse.mean())\n",
    "    rmse_log = (np.log(ground) - np.log(pred)) ** 2\n",
    "    rmse_log = np.sqrt(rmse_log.mean())\n",
    "    abs_rel = np.mean(np.abs(ground - pred) / ground)\n",
    "    sq_rel = np.mean(((ground - pred) ** 2) / ground)\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n",
    "\n",
    "def compute_scale_and_shift(\n",
    "    pred: np.ndarray,\n",
    "    target: np.ndarray,\n",
    "    mask: np.ndarray\n",
    ") -> [float, float]:\n",
    "    \"\"\"From https://gist.github.com/ranftlr/a1c7a24ebb24ce0e2f2ace5bce917022\n",
    "    \"\"\"\n",
    "    # system matrix: A = [[a_00, a_01], [a_10, a_11]]\n",
    "    a_00 = np.sum(mask * pred * pred)\n",
    "    a_01 = np.sum(mask * pred)\n",
    "    a_11 = np.sum(mask)\n",
    "    # right hand side: b = [b_0, b_1]\n",
    "    b_0 = np.sum(mask * pred * target)\n",
    "    b_1 = np.sum(mask * target)\n",
    "    x_0 = np.zeros_like(b_0)\n",
    "    x_1 = np.zeros_like(b_1)\n",
    "    det = a_00 * a_11 - a_01 * a_01\n",
    "    # A needs to be a positive definite matrix.\n",
    "    valid = det > 0\n",
    "    x_0[valid] = (a_11[valid] * b_0[valid] - a_01[valid] * b_1[valid]) / det[valid]\n",
    "    x_1[valid] = (-a_01[valid] * b_0[valid] + a_00[valid] * b_1[valid]) / det[valid]\n",
    "    return x_0, x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825809fa",
   "metadata": {},
   "source": [
    "## Load KITTI and PydNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f51b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KITTI dataset.\n",
    "dataset = KITTI({\n",
    "    \"h\": 320,\n",
    "    \"w\": 640,\n",
    "    \"path\": KITTI_PATH,\n",
    "    \"slice\": SLICE_PATH\n",
    "})\n",
    "\n",
    "# Build PydNet.\n",
    "network = Pydnet({\n",
    "    \"h\": 320,\n",
    "    \"w\": 640,\n",
    "    \"is_training\": False\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1f2e1",
   "metadata": {},
   "source": [
    "## Start Tensorflow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ae05c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../data/checkpoint/pydnet/pydnet\n"
     ]
    }
   ],
   "source": [
    "# Setup KITTI dataset feeding placeholder.\n",
    "pred = network.forward(dataset.batch)\n",
    "pred = tf1.nn.relu(pred)\n",
    "\n",
    "# Setup Tensorflow session and restore checkpoint.\n",
    "save = tf1.train.Saver()\n",
    "sess = tf1.Session()\n",
    "sess.run(tf1.global_variables_initializer())\n",
    "sess.run(dataset.initializer)\n",
    "save.restore(sess, str(CHECK_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f09d78",
   "metadata": {},
   "source": [
    "## Run inference on KITTI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38173eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 697/697 [03:36<00:00,  3.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Makedir output directory.\n",
    "DEST_PATH.mkdir(\n",
    "    parents=True,\n",
    "    exist_ok=True)\n",
    "\n",
    "# Read test file indices.\n",
    "tests = read_lines(SLICE_PATH)\n",
    "    \n",
    "# Run inference on KITTI dataset.\n",
    "with tqdm(total=len(tests)) as pbar:\n",
    "    for i in range(len(tests)):\n",
    "        dep = sess.run(pred)\n",
    "        dep = np.squeeze(dep)\n",
    "        min_dep = dep.min()\n",
    "        max_dep = dep.max()\n",
    "        norm_dep = (dep - min_dep) / (max_dep - min_dep)\n",
    "        norm_dep *= 255.0\n",
    "        target = cv2.imread(str(KITTI_PATH / f\"{tests[i]}.png\"))\n",
    "        h, w = target.shape[:2]\n",
    "        norm_dep = cv2.resize(norm_dep, (w, h))\n",
    "        cv2.imwrite(\n",
    "            str(DEST_PATH / f\"{str(i).zfill(4)}.png\"),\n",
    "            (norm_dep * 256.0).astype(np.uint16))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef8366",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6195f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 697/697 [00:22<00:00, 30.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>abs_rel </td><td style=\"text-align: right;\">0.161777</td></tr>\n",
       "<tr><td>sq_rel  </td><td style=\"text-align: right;\">1.28003 </td></tr>\n",
       "<tr><td>rmse    </td><td style=\"text-align: right;\">6.1434  </td></tr>\n",
       "<tr><td>rmse_log</td><td style=\"text-align: right;\">0.238976</td></tr>\n",
       "<tr><td>a1      </td><td style=\"text-align: right;\">0.759639</td></tr>\n",
       "<tr><td>a2      </td><td style=\"text-align: right;\">0.926482</td></tr>\n",
       "<tr><td>a3      </td><td style=\"text-align: right;\">0.973382</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resulting errors.\n",
    "errors = []\n",
    "\n",
    "# Read test file indices.\n",
    "tests = read_lines(SLICE_PATH)\n",
    "\n",
    "# Read ground truth file.\n",
    "ground = np.load(\n",
    "    GROUND_PATH,\n",
    "    fix_imports=True,\n",
    "    encoding=\"latin1\",\n",
    "    allow_pickle=True)[\"data\"]\n",
    "\n",
    "# Run inference on KITTI dataset.\n",
    "with tqdm(total=len(tests)) as pbar:\n",
    "    for i in range(len(tests)):\n",
    "        target = ground[i]\n",
    "        pred = cv2.imread(\n",
    "            str(DEST_PATH / f\"{str(i).zfill(4)}.png\"),\n",
    "            -1) / 256.0\n",
    "        mask = (target > 1e-3) & (target < MAX_DEPTH)\n",
    "        target_dep = np.zeros_like(target)\n",
    "        target_dep[mask == 1] = 1.0 / target[mask == 1]\n",
    "        scale, shift = compute_scale_and_shift(pred, target_dep, mask)\n",
    "        pred_aligned = scale * pred + shift\n",
    "        disparity_cap = 1.0 / MAX_DEPTH\n",
    "        pred_aligned[pred_aligned < disparity_cap] = disparity_cap\n",
    "        pred_aligned = 1.0 / pred_aligned\n",
    "        pred_aligned = pred_aligned[mask == 1]\n",
    "        target = target[mask == 1]\n",
    "        errors.append(compute_errors(target, pred_aligned))\n",
    "        pbar.update(1)\n",
    "\n",
    "# Print result.\n",
    "mean = np.array(errors).mean(0)\n",
    "table = [\n",
    "    [\"abs_rel\",  mean[0]],\n",
    "    [\"sq_rel\",   mean[1]],\n",
    "    [\"rmse\",     mean[2]],\n",
    "    [\"rmse_log\", mean[3]],\n",
    "    [\"a1\",       mean[4]], \n",
    "    [\"a2\",       mean[5]], \n",
    "    [\"a3\",       mean[6]]]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d0616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
